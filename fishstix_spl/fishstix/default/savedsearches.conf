[collect_introspection_restore_metrics]
action.webhook.enable_allowlist = 0
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = */5 * * * *
description = summary of metrics from _introspection in 1 hour intervals
dispatch.earliest_time = -1h
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = index=_introspection "restored_data_100" component=PerProcess \
| rex field=data.args "(?<bucket_id>db.\d+.\d+.\d+).tmp" \
| rex field=data.args "\s+/mnt/data/(?<dest_index>.{1,25})/thawedd" \
| bucket _time span=1s | stats max(data.normalized_pct_cpu) AS max_normalized_pct_cpu max(data.mem_used) AS max_mem_used sum(data.read_mb) AS read_mb sum(data.written_mb) AS write_mb sum(data.elapsed) AS dur_seconds by bucket_id dest_index _time  \
| table _time bucket_id dest_index read_mb write_mb dur_seconds max*  \
| eval max_normalized_pct_cpu=if(isnull(max_normalized_pct_cpu),"0.00",max_normalized_pct_cpu) \
| collect index=fx_jobs


[update_q_counters]
action.webhook.enable_allowlist = 0
alert.digest_mode = 0
alert.expires = 999d
alert.severity = 1
alert.suppress = 0
alert.track = 1
counttype = number of events
cron_schedule = */1 * * * *
description = polls the Redis Q via the 2 custom commands for updates for each queue
dispatch.earliest_time = @d
dispatch.latest_time = now
enableSched = 1
quantity = 0
relation = greater than
search = | makeresults  redis="redis" | restoreqcounter | append [| makeresults  redis="redis" | copyqcounter]
